[["index.html", "Introduction to OpenRefine Chapter1 Welcome 1.1 Pre-Class Prep 1.2 Learning Objectives 1.3 Class Data 1.4 About the Instructor", " Introduction to OpenRefine Ariel Deardorff, Data Services Librian, UCSF Library 2020-11-03 Chapter1 Welcome Got messy spreadsheets? OpenRefine is a powerful, free, open-source software tool for cleaning and transforming data in a way that is easy to reproduce. This hands-on class is targeted at people who need to clean messy data, including spreadsheets of survey responses, patient encounters, financial records, or workshop attendance. Together we will work through the basics of cleaning data in OpenRefine and also go over some more advanced techniques including pulling in additional data from an API. If you want something more powerful than Excel but don't want to spend the time to learn a programming language like R or Python, OpenRefine could be the perfect tool for you! 1.1 Pre-Class Prep Before joining the workshop please complete the following activities: Download OpenRefine Note that depending on your operating system you may also need to download java Download the class data 1.2 Learning Objectives By the end of the class learners should be able to: Explain how OpenRefine works on their computer Use OpenRefine to: Split data into multiple columns Facet data to find typos and errors Cluster data to easily correct typos at scale Pull in additional data from an API Transform wide data into tidy data format Export their cleaned data in a variety of formats Save their cleaning scripts so they can be re-used 1.3 Class Data The data for this class was pulled from the National Library of Medicine Dietary Supplements Label Database. The version we are using has been intentionally “dirtied” to introduce errors and typos. 1.4 About the Instructor Ariel Deardorff is the Data Services Librarian at UCSF, and member of the Library's Data Science Initiative team. She teaches classes and does research on data management, open science, and reproducibility in the health sciences. For questions about this course or other courses email ariel.deardorff@ucsf.edu or visit the Data Science Initiative Website This work is licensed under a Creative Commons Attribution 4.0 International License. "],["getting-to-know-our-data-and-tools.html", "Chapter2 Getting to Know our Data and Tools 2.1 What is OpenRefine? 2.2 Exploring the Data 2.3 Uploading Data Into OpenRefine 2.4 The OpenRefine Interface", " Chapter2 Getting to Know our Data and Tools Let's get to know our data and learn the basics of OpenRefine. 2.1 What is OpenRefine? OpenRefine (formerly Google Refine) is an open-source tool for cleaning data. With OpenRefine you can: Identify and fix typos and errors in relatively large datasets (100,000 rows) fast Track all of your cleaning steps so you know exactly what changes you made Keep your raw data raw and export a cleaned version Re-run the same data cleaning steps on future datasets An important thing to know about OpenRefine is that while it opens in your browser it is actually a java-based tool that is running on your computer, and therefore does not require internet access. 2.2 Exploring the Data Now let's take a look at our data. Open the spreadsheet “NewOpenRefine_Data1.csv” in excel. Scenario: You want to learn more about different supplements over time so have downloaded a copy of the National Library of Medicine Dietary Supplements Label Database. Before you can start your analysis you want to check for missing/incorrect data. (Note that this copy of the data has been intentionally altered) 2.3 Uploading Data Into OpenRefine Open OpenRefine (you might need to say Allow to run the first time or change security settings) – note that it opens in a browser at http://127.0.0.1:3333/ On the main page we have three main tabs: Create Project – to create a new project from scratch – this is what we will be using today Open Project - for an OpenRefine project you have previously worked on Import Project – to import an OpenRefine project from someone else Select Create Project and since we are uploading a file we will click Get data from &gt; This computer &gt; Browse Choose our file (&quot;NewOpenRefine_Data1.csv&quot;) and hit Next The next screen is where we can preview our data to double check everything is being read in correctly When everything looks good you select Create Project in the upper right corner 2.4 The OpenRefine Interface On the left of the OpenRefine workspace you will find two tabs: Facet/Filter and Undo/Redo Facet/Filter is where we will see our different facets and filters appear as we click on them Undo/Redo is how we undo changes – note that OpenRefine does not have a “back” button. In the middle you will find your data – note that you can select how many rows you want to see at once – from 5 to 50. If you have a large dataset or don’t want to see all your columns at once you can re-arrange or hide your columns To re-arrange/hide all columns you can go to the first column All, click the drop down menu, select Edit columns &gt; Re-order/remove columns. Then you can re-order them or remove ones you don’t need Alternatively, you can click on a specific column and then choose View &gt; Collapse all the right/left To undo this action you need to click All &gt; Expand all columns "],["basic-data-cleaning-with-openrefine.html", "Chapter3 Basic Data Cleaning with OpenRefine 3.1 Splitting Columns 3.2 Undo/Redo 3.3 Faceting Data 3.4 Trimming Whitespace and Changing to Titlecase 3.5 Clustering Data 3.6 Sorting", " Chapter3 Basic Data Cleaning with OpenRefine Let's dive into our data with some basic exploration and cleaning. 3.1 Splitting Columns Sometimes you have more than one data point in a column and need to separate it out so you can analyze it separately (similar to the Text to columns operations in Excel) Let's split Serving Size into two columns – one for the amount and one for the unit Using the drop-down menu select Edit Column &gt; Split into several Columns - by separator (change to a blank space) &gt; split into 2 columns at most &gt; uncheck remove this column We now have two new columns – one called Serving Size 1 and one called Serving Size 2 let’s rename them Serving Amount and Serving Unit by clicking on Edit column &gt; Rename this column Challenge: Use the split feature to divide the Date Entered into DSLD column into two columns, one for date and one for time. Can we conclude anything about the times? 3.2 Undo/Redo When we make a mistake in OpenRefine, we use Undo/Redo rather than a back button. Let’s say we didn’t actually want to split Date Entered into DSLD into two columns. Click on Undo/Redo and select the action before the one we just did. Our split has now disappeared. 3.3 Faceting Data Faceting is one of the best parts of OpenRefine and can be used in a variety of ways including to get a snapshot of unique variables and to spot potential errors in your data. Let's facet to get a snapshot of our data: We can scroll down to see if our splits have worked correctly but it is always smart to double check with a facet. Let’s get a snapshot of our new Serving Unit column by selecting Facet &gt; Text facet On the left we can now see a list of all the different values in this column in alphabetical order or by count. There should be 433 choices. If we click on any of the options we will filter to just those rows. Some of the Serving Units look a little odd, but they were actually provided that way by the manufacturer so we will leave them for now. Challenge: What Brand makes a supplement that comes in the form of &quot;Gummy Dolphin(s)&quot;? Challenge: Use the Facet feature on the Serving Amount column. How many unique variables are there? What is the most frequent serving amount? Now let's use faceting to find some potential mistakes: Now let’s try faceting the LanguaL-Product Type column. It looks like we have 14 choices but some of these look a little odd. For example, it looks like we have 25 records for Amino acid/protein [A1305 and 2325 records for Amino acid/protein [A1305]. In this case we know that those 25 records should say [A1305].To fix this, we can click Edit next to those records, update the records, and select Apply. No we have 13 choices It looks like there are a couple more spelling mistakes in this column, we could fix them manually as we did above, but let’s hold off and use the clustering feature later. Challenge: Facet the Brands Names column, how many options are there? Do you see any potential mistakes? Challenge: Explore the other kinds of facets, do any of these seem useful to you? 3.4 Trimming Whitespace and Changing to Titlecase Some of the names in our Brand Name column look very similar. Before we spend a lot of time trying to manually clean or cluster all 1781 of them let’s try two easy cleaning steps. First, let’s trim any whitespace at the beginning or end of the row on the Brand Name column by selecting Edit cells &gt; Common transforms &gt; Trim leading and trailing whitespace – already our total number has come down to 1778 Next, let’s change everything to titlecase by selecting Edit cells &gt; Common transforms &gt; To titlecase – now we have 1693 options. 3.5 Clustering Data Now let’s clean up the rest of our Brand Name column using Clustering! Clustering is one of the most powerful features in OpenRefine! Clustering is a tool for grouping names that are similar so that we can bulk edit them – it works on the syntactic level (spelling) not semantic (meaning) In the Facet window for our column, let’s hit Cluster in the upper right-hand corner OpenRefine uses two main algorithms for clustering the data: key collision: generates a key from a value based on common transformations (what is the core value when you remove whitespace/capitalization/punctuation) nearest neighbor: each unique value is compared to every other unique value using a distance function Fortunately, we don’t really need to understand the algorithms because it is easy to try them all! In the clustering box we can see: Cluster Size: how many different options in that cluster Row Count: how many rows will be changed Values in Cluster: possible options Merge?: check box if you wish to merge those cells New cell value: what the cell should say Start with the Key Collision Method and work your way through the Keying function – there should be many options to cluster. If they all look good you can use Select all in the bottom left (note that you might need to decrease the size of your window to see this) If the selected replacement looks correct we can check the Merge box and then click Merge selected and re-cluster at the bottom As you work through the remaining algorithms you might see that some work better than others. Take a look at all the options but only cluster using the Key Collision – fingerprint, ngram fingerprint and Nearest Neighbor – levenshtein You should have approximately 1625 choices now (but don’t worry if you don’t have the same number) Challenge: Which methods and keying functions do not seem like they will work for the Brand Name column? Challenge: Facet and Cluster the LanguaL-Product Type column. How many unique variables do you end up with? 3.6 Sorting Right now the data is sorted by Brand Name first, what if we wanted to sort by DSLD ID? Under DSLD ID select Sort and we want to sort by numbers. Note that we can position errors and blanks at the beginning to help us spot them if we want. Hit Ok when you are happy with your sort. You can edit your sort by selecting Sort again under the specific column. You can also select Sort &gt; Reverse or Remove sort to undo (since it is not listed in the Undo/redo column). Note that this didn't add any steps to the Undo/Redo - the sort is not permanent If we wanted it to be permanent we would select Sort in the top middle &gt; Reorder rows permanently We can sort by multiple things, just sort each row in the order you want them sorted (view the order in the sort menu) ex: sort DSLD ID then Brand Name "],["advanced-openrefine.html", "Chapter4 Advanced OpenRefine 4.1 Pulling data from an API 4.2 Extracting the Data", " Chapter4 Advanced OpenRefine In addition to the basic data cleaning features, OpenRefine has a variety of advanced features. Here we will go over how to pull in data from external sources and add it to our spreadsheet. To learn more about other advanced features, check out the Recommended Resources page. 4.1 Pulling data from an API Our current spreadsheet is missing some data about the tracking history of these products. Luckily, this data is available in the National Library of Medicine's Dietary Supplements Label Database and we can access it via an application programming interface (API). To learn more about this particular database and API you can visit the website. Before we add a bunch of new data, let’s test our script on a couple of records. Go ahead and star two records using the little star icon on the far left of each record. Then, under All &gt; Facet &gt; Facet by star and select TRUE in the facet box on the left. Now we can work with these two records. Now we want to pull new data from the database using the DSLD ID number. Under the DSLD ID column select &gt; Edit column &gt; Add column by fetching URLs In the box enter: &quot;https://datadiscovery.nlm.nih.gov/resource/wp6t-qxsk.json?dsld_id=&quot;+value this is the URL of the API plus a stand-in for the ID number (the +value). You should see a preview of the URL with the ID at the end. Name the new column JSON and hit OK. It might take a minute or so to load but eventually we should get a new column called JSON with a paragraph of text in JSON format. 4.2 Extracting the Data JSON, or JavaScript Object Notation is a text format for storing and sharing data, often in lists or dictionaries. We basically asked the NLM database to send us all the info they have for this ID. Now we need to extract the info we want and put it in a new column Under the JSON column select Edit column &gt; Add column based on this column In the box write: value.parseJson()[0][&quot;tracking_history&quot;]. This is a GREL (google refine experssion language) command that tells OpenRefine to extract the relevant bit of the JSON data by pulling the first list of items [0] and then pulling the data that corresponds with the Tracking history segment. When you are done name this column Tracking History and hit OK. Now we should have a new column called &quot;Tracking History&quot; with the relevant info from the JSON text. You can learn more about parsing JSON in this UCSF library class: Reading Data from an API with Python and JSON. There are a ton of ways to add more info to OpenRefine. In addition to adding new data you can also reconcile the data you have by pulling in official lists of names/businesses/authors from a site like Wikidata (more info in the resources section at the end). Challenge: add a new column containing the database info from the JSON. Hint: look at the History tab in your GREL workspace to see your previous commands. "],["exporting-cleaned-data-and-scripts.html", "Chapter5 Exporting Cleaned Data and Scripts", " Chapter5 Exporting Cleaned Data and Scripts The OpenRefine project has been saving as you go - but not altering your underlying data (this is a good thing!) To export the cleaned version of our data we need to click Export (top left corner) then choose the type of file (CSV or Excel) We recommend that you rename your new file with a title like &quot;dataxyz_cleaned&quot; so you know that it is the cleaned version. What if we are going to get more of this same kind of data over and over and want to apply the same changes? We could export our cleaning script and then re-run it on new data. In the Undo/Redo section click Extract - select the steps you want to save (this is also where you can see the detailed step by step record of all of your changes!) Then copy and paste the code into a text editor (like Text Wrangler/Text Edit) and save as a txt file (probably in the same folder as your data or with other scripts you use) To apply the script to new data, you need to open a project with your new data - go to Undo/redo &gt; Apply enter the plain text from your file hit Perform Operations and blammo it will re-run all the same data cleaning steps on your new dataset! "],["recommended-resources-and-tutorials.html", "Chapter6 Recommended Resources and Tutorials", " Chapter6 Recommended Resources and Tutorials Here are some places to learn more about OpenRefine: OpenRefine Website Library Carpentry - OpenRefine (heavily used for the basis of this lesson) Data Carpentry – OpenRefine for Social Science Data Grateful Dead OpenRefine Tutorial Programming Historian - Fetching and Parsing Data with OpenRefine Fetching URLS from OpenRefine Reconciling Data with OpenRefine "]]
